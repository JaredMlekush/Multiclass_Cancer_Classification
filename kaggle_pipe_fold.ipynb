{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import base\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test set\n",
    "train = pd.read_csv('train_ml2_2021.csv')\n",
    "test = pd.read_csv('test_ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine problem_id and target and set \"-1\" placeholder for 'fold' column\n",
    "train['combined_target'] = train.problem_id.astype(str) + train.target.astype(str)\n",
    "train['fold'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v971</th>\n",
       "      <th>v972</th>\n",
       "      <th>v973</th>\n",
       "      <th>v974</th>\n",
       "      <th>v975</th>\n",
       "      <th>v976</th>\n",
       "      <th>v977</th>\n",
       "      <th>target</th>\n",
       "      <th>combined_target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8297</th>\n",
       "      <td>20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8298</th>\n",
       "      <td>20</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8299</th>\n",
       "      <td>20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8300</th>\n",
       "      <td>20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>20</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8302 rows × 982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      problem_id    v0    v1    v2    v3    v4    v5    v6    v7    v8  ...  \\\n",
       "0              0  0.35  0.36  0.77  0.42  0.48  0.12  0.43  0.49  0.19  ...   \n",
       "1              0  0.12  0.17  0.38  0.43  0.57  0.09  0.11  0.58  0.35  ...   \n",
       "2              0  0.67  0.16  0.85  0.41  0.57  0.27  0.83  0.73  0.26  ...   \n",
       "3              0  0.70  0.20  0.62  0.41  0.41  0.10  0.80  0.52  0.82  ...   \n",
       "4              0  0.72  0.75  0.74  0.42  0.41  0.76  0.34  0.72  0.06  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "8297          20  0.91  0.76  0.45  0.81  0.99  0.20  0.36  0.28  0.02  ...   \n",
       "8298          20  0.31  0.93  0.45  0.61  0.99  0.09  0.73  0.25  0.56  ...   \n",
       "8299          20  0.92  0.82  0.52  0.61  0.94  0.67  0.65  0.34  0.25  ...   \n",
       "8300          20  0.93  0.85  0.51  0.64  0.95  0.76  0.76  0.36  0.07  ...   \n",
       "8301          20  0.87  0.14  0.52  0.64  0.03  0.94  0.45  0.50  0.12  ...   \n",
       "\n",
       "      v971  v972  v973  v974  v975  v976  v977  target  combined_target  fold  \n",
       "0     0.56  0.40  0.75  0.08  0.14  0.43  0.88       0               00    -1  \n",
       "1     0.06  0.17  0.09  0.04  0.04  0.45  0.14       1               01    -1  \n",
       "2     0.57  0.58  0.37  0.01  0.10  0.38  0.06       1               01    -1  \n",
       "3     0.25  0.07  0.23  0.04  0.76  0.41  0.59       1               01    -1  \n",
       "4     0.16  0.03  0.21  0.10  0.12  0.53  0.30       1               01    -1  \n",
       "...    ...   ...   ...   ...   ...   ...   ...     ...              ...   ...  \n",
       "8297  0.86  0.84  0.86  0.52  0.04  0.77  0.68       0              200    -1  \n",
       "8298  0.61  0.65  0.65  0.31  0.06  0.89  0.11       0              200    -1  \n",
       "8299  0.94  0.76  0.61  0.72  0.14  0.11  0.91       0              200    -1  \n",
       "8300  0.24  0.89  0.84  0.54  0.13  0.91  0.95       0              200    -1  \n",
       "8301  0.72  0.78  0.75  0.71  0.38  0.19  0.91       1              201    -1  \n",
       "\n",
       "[8302 rows x 982 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFold which serves as cross validation - in this case split into 5 different groups\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True,  random_state=42)\n",
    "\n",
    "for fold_id, (train_idx, valid_idx) in enumerate(skf.split(train, train.combined_target)):\n",
    "    train.loc[valid_idx, 'fold'] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v971</th>\n",
       "      <th>v972</th>\n",
       "      <th>v973</th>\n",
       "      <th>v974</th>\n",
       "      <th>v975</th>\n",
       "      <th>v976</th>\n",
       "      <th>v977</th>\n",
       "      <th>target</th>\n",
       "      <th>combined_target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8297</th>\n",
       "      <td>20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8298</th>\n",
       "      <td>20</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8299</th>\n",
       "      <td>20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8300</th>\n",
       "      <td>20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>20</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8302 rows × 982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      problem_id    v0    v1    v2    v3    v4    v5    v6    v7    v8  ...  \\\n",
       "0              0  0.35  0.36  0.77  0.42  0.48  0.12  0.43  0.49  0.19  ...   \n",
       "1              0  0.12  0.17  0.38  0.43  0.57  0.09  0.11  0.58  0.35  ...   \n",
       "2              0  0.67  0.16  0.85  0.41  0.57  0.27  0.83  0.73  0.26  ...   \n",
       "3              0  0.70  0.20  0.62  0.41  0.41  0.10  0.80  0.52  0.82  ...   \n",
       "4              0  0.72  0.75  0.74  0.42  0.41  0.76  0.34  0.72  0.06  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "8297          20  0.91  0.76  0.45  0.81  0.99  0.20  0.36  0.28  0.02  ...   \n",
       "8298          20  0.31  0.93  0.45  0.61  0.99  0.09  0.73  0.25  0.56  ...   \n",
       "8299          20  0.92  0.82  0.52  0.61  0.94  0.67  0.65  0.34  0.25  ...   \n",
       "8300          20  0.93  0.85  0.51  0.64  0.95  0.76  0.76  0.36  0.07  ...   \n",
       "8301          20  0.87  0.14  0.52  0.64  0.03  0.94  0.45  0.50  0.12  ...   \n",
       "\n",
       "      v971  v972  v973  v974  v975  v976  v977  target  combined_target  fold  \n",
       "0     0.56  0.40  0.75  0.08  0.14  0.43  0.88       0               00     4  \n",
       "1     0.06  0.17  0.09  0.04  0.04  0.45  0.14       1               01     1  \n",
       "2     0.57  0.58  0.37  0.01  0.10  0.38  0.06       1               01     1  \n",
       "3     0.25  0.07  0.23  0.04  0.76  0.41  0.59       1               01     4  \n",
       "4     0.16  0.03  0.21  0.10  0.12  0.53  0.30       1               01     3  \n",
       "...    ...   ...   ...   ...   ...   ...   ...     ...              ...   ...  \n",
       "8297  0.86  0.84  0.86  0.52  0.04  0.77  0.68       0              200     3  \n",
       "8298  0.61  0.65  0.65  0.31  0.06  0.89  0.11       0              200     4  \n",
       "8299  0.94  0.76  0.61  0.72  0.14  0.11  0.91       0              200     4  \n",
       "8300  0.24  0.89  0.84  0.54  0.13  0.91  0.95       0              200     2  \n",
       "8301  0.72  0.78  0.75  0.71  0.38  0.19  0.91       1              201     2  \n",
       "\n",
       "[8302 rows x 982 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the un-needed 'combined_target' column\n",
    "train.drop('combined_target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test sets\n",
    "test_X, test_y = test.iloc[:,:-1], test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4124\n",
       "1    3175\n",
       "2     729\n",
       "3     255\n",
       "4      19\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the data - Imbalaced\n",
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imbalanced multiclass target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8302 entries, 0 to 8301\n",
      "Columns: 981 entries, problem_id to fold\n",
      "dtypes: float64(978), int64(3)\n",
      "memory usage: 62.1 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training sets\n",
    "X, y = train.iloc[:,:-1], train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-14 01:49:42,728]\u001b[0m A new study created in memory with name: no-name-d999d21e-cac1-4e12-8ce2-971711b9d99a\u001b[0m\n",
      "\u001b[32m[I 2021-07-14 01:50:11,696]\u001b[0m Trial 0 finished with value: 0.9416987153913666 and parameters: {'rf_max_depth': 53, 'rf_min_leaf': 5, 'rf_n_estimators': 300}. Best is trial 0 with value: 0.9416987153913666.\u001b[0m\n",
      "\u001b[32m[I 2021-07-14 01:50:32,868]\u001b[0m Trial 1 finished with value: 0.9173697076082779 and parameters: {'rf_max_depth': 43, 'rf_min_leaf': 2, 'rf_n_estimators': 200}. Best is trial 0 with value: 0.9416987153913666.\u001b[0m\n",
      "\u001b[32m[I 2021-07-14 01:50:52,249]\u001b[0m Trial 2 finished with value: 0.9355583441532536 and parameters: {'rf_max_depth': 55, 'rf_min_leaf': 5, 'rf_n_estimators': 200}. Best is trial 0 with value: 0.9416987153913666.\u001b[0m\n",
      "\u001b[32m[I 2021-07-14 01:51:11,249]\u001b[0m Trial 3 finished with value: 0.9268844432516339 and parameters: {'rf_max_depth': 9, 'rf_min_leaf': 4, 'rf_n_estimators': 300}. Best is trial 0 with value: 0.9416987153913666.\u001b[0m\n",
      "\u001b[33m[W 2021-07-14 01:51:15,352]\u001b[0m Trial 4 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[32m[I 2021-07-14 01:51:57,921]\u001b[0m Trial 5 finished with value: 0.9164067226159303 and parameters: {'rf_max_depth': 27, 'rf_min_leaf': 1, 'rf_n_estimators': 400}. Best is trial 0 with value: 0.9416987153913666.\u001b[0m\n",
      "\u001b[32m[I 2021-07-14 01:52:12,980]\u001b[0m Trial 6 finished with value: 0.9260416500438842 and parameters: {'rf_max_depth': 13, 'rf_min_leaf': 3, 'rf_n_estimators': 200}. Best is trial 0 with value: 0.9416987153913666.\u001b[0m\n",
      "\u001b[32m[I 2021-07-14 01:52:31,548]\u001b[0m Trial 7 finished with value: 0.9253190486207321 and parameters: {'rf_max_depth': 8, 'rf_min_leaf': 5, 'rf_n_estimators': 400}. Best is trial 0 with value: 0.9416987153913666.\u001b[0m\n",
      "\u001b[32m[I 2021-07-14 01:52:49,322]\u001b[0m Trial 8 finished with value: 0.9379680552432486 and parameters: {'rf_max_depth': 58, 'rf_min_leaf': 5, 'rf_n_estimators': 200}. Best is trial 0 with value: 0.9416987153913666.\u001b[0m\n",
      "\u001b[32m[I 2021-07-14 01:53:27,017]\u001b[0m Trial 9 finished with value: 0.926282106148858 and parameters: {'rf_max_depth': 31, 'rf_min_leaf': 2, 'rf_n_estimators': 400}. Best is trial 0 with value: 0.9416987153913666.\u001b[0m\n",
      "\u001b[32m[I 2021-07-14 01:53:56,555]\u001b[0m Trial 10 finished with value: 0.9180918012809819 and parameters: {'rf_max_depth': 26, 'rf_min_leaf': 1, 'rf_n_estimators': 300}. Best is trial 0 with value: 0.9416987153913666.\u001b[0m\n",
      "\u001b[33m[W 2021-07-14 01:53:57,119]\u001b[0m Trial 11 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-07-14 01:53:57,740]\u001b[0m Trial 12 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-07-14 01:53:58,300]\u001b[0m Trial 13 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-07-14 01:53:58,956]\u001b[0m Trial 14 failed, because the objective function returned nan.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Invoke suggest methods of a Trial object to generate hyperparameters.\n",
    "    \n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 8, 64)\n",
    "    rf_min_leaf = trial.suggest_int('rf_min_leaf', 1, 5)\n",
    "    rf_n_estimators = trial.suggest_int('rf_n_estimators', 0, 400, step=100)\n",
    "    clf= RandomForestClassifier(max_depth=rf_max_depth, min_samples_leaf=rf_min_leaf, n_estimators=rf_n_estimators, class_weight='balanced' ,n_jobs=-1)\n",
    "\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    scoring = ['accuracy', 'neg_log_loss']\n",
    "    scores = cross_validate(clf, X, y, cv=cv, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "    accuracy_score = scores['test_accuracy'].mean()\n",
    "\n",
    "\n",
    "    return accuracy_score  # An objective value linked with the Trial object.\n",
    "\n",
    "study = optuna.create_study(direction='maximize')  # Create a new study.\n",
    "study.optimize(objective, n_trials=15)  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v970</th>\n",
       "      <th>v971</th>\n",
       "      <th>v972</th>\n",
       "      <th>v973</th>\n",
       "      <th>v974</th>\n",
       "      <th>v975</th>\n",
       "      <th>v976</th>\n",
       "      <th>v977</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8297</th>\n",
       "      <td>20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8298</th>\n",
       "      <td>20</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8299</th>\n",
       "      <td>20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8300</th>\n",
       "      <td>20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>20</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8302 rows × 981 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      problem_id    v0    v1    v2    v3    v4    v5    v6    v7    v8  ...  \\\n",
       "0              0  0.35  0.36  0.77  0.42  0.48  0.12  0.43  0.49  0.19  ...   \n",
       "1              0  0.12  0.17  0.38  0.43  0.57  0.09  0.11  0.58  0.35  ...   \n",
       "2              0  0.67  0.16  0.85  0.41  0.57  0.27  0.83  0.73  0.26  ...   \n",
       "3              0  0.70  0.20  0.62  0.41  0.41  0.10  0.80  0.52  0.82  ...   \n",
       "4              0  0.72  0.75  0.74  0.42  0.41  0.76  0.34  0.72  0.06  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "8297          20  0.91  0.76  0.45  0.81  0.99  0.20  0.36  0.28  0.02  ...   \n",
       "8298          20  0.31  0.93  0.45  0.61  0.99  0.09  0.73  0.25  0.56  ...   \n",
       "8299          20  0.92  0.82  0.52  0.61  0.94  0.67  0.65  0.34  0.25  ...   \n",
       "8300          20  0.93  0.85  0.51  0.64  0.95  0.76  0.76  0.36  0.07  ...   \n",
       "8301          20  0.87  0.14  0.52  0.64  0.03  0.94  0.45  0.50  0.12  ...   \n",
       "\n",
       "      v970  v971  v972  v973  v974  v975  v976  v977  target  fold  \n",
       "0     0.57  0.56  0.40  0.75  0.08  0.14  0.43  0.88       0     4  \n",
       "1     0.59  0.06  0.17  0.09  0.04  0.04  0.45  0.14       1     2  \n",
       "2     0.42  0.57  0.58  0.37  0.01  0.10  0.38  0.06       1     1  \n",
       "3     0.52  0.25  0.07  0.23  0.04  0.76  0.41  0.59       1     3  \n",
       "4     0.41  0.16  0.03  0.21  0.10  0.12  0.53  0.30       1     1  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...     ...   ...  \n",
       "8297  0.92  0.86  0.84  0.86  0.52  0.04  0.77  0.68       0     0  \n",
       "8298  0.93  0.61  0.65  0.65  0.31  0.06  0.89  0.11       0     2  \n",
       "8299  0.74  0.94  0.76  0.61  0.72  0.14  0.11  0.91       0     4  \n",
       "8300  0.92  0.24  0.89  0.84  0.54  0.13  0.91  0.95       0     4  \n",
       "8301  0.83  0.72  0.78  0.75  0.71  0.38  0.19  0.91       1     1  \n",
       "\n",
       "[8302 rows x 981 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-14 14:55:43,721]\u001b[0m A new study created in memory with name: no-name-e65243c4-37da-46f9-850c-a9221c9d7178\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 14:56:07,985]\u001b[0m Trial 0 finished with value: 0.704168050891102 and parameters: {'rf_max_depth': 4, 'rf_max_leaves': 39, 'rf_n_estimators': 140}. Best is trial 0 with value: 0.704168050891102.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 14:57:13,828]\u001b[0m Trial 1 finished with value: 0.7136824238555667 and parameters: {'rf_max_depth': 17, 'rf_max_leaves': 36, 'rf_n_estimators': 120}. Best is trial 1 with value: 0.7136824238555667.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 14:57:40,195]\u001b[0m Trial 2 finished with value: 0.7113929770859476 and parameters: {'rf_max_depth': 6, 'rf_max_leaves': 40, 'rf_n_estimators': 80}. Best is trial 1 with value: 0.7136824238555667.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 14:58:46,181]\u001b[0m Trial 3 finished with value: 0.7148876783473448 and parameters: {'rf_max_depth': 21, 'rf_max_leaves': 32, 'rf_n_estimators': 140}. Best is trial 3 with value: 0.7148876783473448.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 14:59:18,859]\u001b[0m Trial 4 finished with value: 0.7165745704068531 and parameters: {'rf_max_depth': 12, 'rf_max_leaves': 33, 'rf_n_estimators': 70}. Best is trial 4 with value: 0.7165745704068531.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 14:59:30,644]\u001b[0m Trial 5 finished with value: 0.7006759609177228 and parameters: {'rf_max_depth': 6, 'rf_max_leaves': 35, 'rf_n_estimators': 30}. Best is trial 4 with value: 0.7165745704068531.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 14:59:39,943]\u001b[0m Trial 6 finished with value: 0.6960984455582716 and parameters: {'rf_max_depth': 6, 'rf_max_leaves': 35, 'rf_n_estimators': 20}. Best is trial 4 with value: 0.7165745704068531.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:00:46,161]\u001b[0m Trial 7 finished with value: 0.7172965190080007 and parameters: {'rf_max_depth': 28, 'rf_max_leaves': 39, 'rf_n_estimators': 130}. Best is trial 7 with value: 0.7172965190080007.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:01:49,089]\u001b[0m Trial 8 finished with value: 0.7098325874237468 and parameters: {'rf_max_depth': 11, 'rf_max_leaves': 31, 'rf_n_estimators': 150}. Best is trial 7 with value: 0.7172965190080007.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:02:02,259]\u001b[0m Trial 9 finished with value: 0.69694087608713 and parameters: {'rf_max_depth': 31, 'rf_max_leaves': 30, 'rf_n_estimators': 20}. Best is trial 7 with value: 0.7172965190080007.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:03:01,045]\u001b[0m Trial 10 finished with value: 0.7138036311410604 and parameters: {'rf_max_depth': 32, 'rf_max_leaves': 38, 'rf_n_estimators': 100}. Best is trial 7 with value: 0.7172965190080007.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:03:34,702]\u001b[0m Trial 11 finished with value: 0.711515997765898 and parameters: {'rf_max_depth': 24, 'rf_max_leaves': 33, 'rf_n_estimators': 60}. Best is trial 7 with value: 0.7172965190080007.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:04:06,359]\u001b[0m Trial 12 finished with value: 0.7134428381799321 and parameters: {'rf_max_depth': 12, 'rf_max_leaves': 37, 'rf_n_estimators': 60}. Best is trial 7 with value: 0.7172965190080007.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:04:54,891]\u001b[0m Trial 13 finished with value: 0.7130808846463518 and parameters: {'rf_max_depth': 26, 'rf_max_leaves': 33, 'rf_n_estimators': 100}. Best is trial 7 with value: 0.7172965190080007.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:05:22,361]\u001b[0m Trial 14 finished with value: 0.7097077533493396 and parameters: {'rf_max_depth': 14, 'rf_max_leaves': 33, 'rf_n_estimators': 50}. Best is trial 7 with value: 0.7172965190080007.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:06:13,750]\u001b[0m Trial 15 finished with value: 0.7128409362918259 and parameters: {'rf_max_depth': 18, 'rf_max_leaves': 34, 'rf_n_estimators': 90}. Best is trial 7 with value: 0.7172965190080007.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:07:23,279]\u001b[0m Trial 16 finished with value: 0.7136841647142453 and parameters: {'rf_max_depth': 28, 'rf_max_leaves': 40, 'rf_n_estimators': 120}. Best is trial 7 with value: 0.7172965190080007.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:08:17,001]\u001b[0m Trial 17 finished with value: 0.7195866185996243 and parameters: {'rf_max_depth': 10, 'rf_max_leaves': 37, 'rf_n_estimators': 120}. Best is trial 17 with value: 0.7195866185996243.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:09:16,615]\u001b[0m Trial 18 finished with value: 0.7152495593451471 and parameters: {'rf_max_depth': 21, 'rf_max_leaves': 38, 'rf_n_estimators': 120}. Best is trial 17 with value: 0.7195866185996243.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:10:16,092]\u001b[0m Trial 19 finished with value: 0.7181404727882027 and parameters: {'rf_max_depth': 9, 'rf_max_leaves': 37, 'rf_n_estimators': 150}. Best is trial 17 with value: 0.7195866185996243.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:10:28,970]\u001b[0m Trial 20 finished with value: 0.6940503978587438 and parameters: {'rf_max_depth': 2, 'rf_max_leaves': 37, 'rf_n_estimators': 150}. Best is trial 17 with value: 0.7195866185996243.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:11:26,029]\u001b[0m Trial 21 finished with value: 0.71657428026374 and parameters: {'rf_max_depth': 10, 'rf_max_leaves': 38, 'rf_n_estimators': 130}. Best is trial 17 with value: 0.7195866185996243.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:12:06,982]\u001b[0m Trial 22 finished with value: 0.7100726083140508 and parameters: {'rf_max_depth': 8, 'rf_max_leaves': 36, 'rf_n_estimators': 110}. Best is trial 17 with value: 0.7195866185996243.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:13:18,017]\u001b[0m Trial 23 finished with value: 0.7198260592037021 and parameters: {'rf_max_depth': 15, 'rf_max_leaves': 39, 'rf_n_estimators': 150}. Best is trial 23 with value: 0.7198260592037021.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:14:25,293]\u001b[0m Trial 24 finished with value: 0.718502353786005 and parameters: {'rf_max_depth': 13, 'rf_max_leaves': 37, 'rf_n_estimators': 150}. Best is trial 23 with value: 0.7198260592037021.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:15:32,777]\u001b[0m Trial 25 finished with value: 0.7187417218543046 and parameters: {'rf_max_depth': 15, 'rf_max_leaves': 39, 'rf_n_estimators': 140}. Best is trial 23 with value: 0.7198260592037021.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:16:38,032]\u001b[0m Trial 26 finished with value: 0.7200669505233457 and parameters: {'rf_max_depth': 15, 'rf_max_leaves': 39, 'rf_n_estimators': 130}. Best is trial 26 with value: 0.7200669505233457.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:17:34,925]\u001b[0m Trial 27 finished with value: 0.7104304273082697 and parameters: {'rf_max_depth': 19, 'rf_max_leaves': 40, 'rf_n_estimators': 110}. Best is trial 26 with value: 0.7200669505233457.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:18:38,568]\u001b[0m Trial 28 finished with value: 0.7200669505233457 and parameters: {'rf_max_depth': 15, 'rf_max_leaves': 39, 'rf_n_estimators': 130}. Best is trial 26 with value: 0.7200669505233457.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:19:41,920]\u001b[0m Trial 29 finished with value: 0.7198272197761546 and parameters: {'rf_max_depth': 16, 'rf_max_leaves': 39, 'rf_n_estimators': 130}. Best is trial 26 with value: 0.7200669505233457.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:20:45,586]\u001b[0m Trial 30 finished with value: 0.7166938192263334 and parameters: {'rf_max_depth': 20, 'rf_max_leaves': 39, 'rf_n_estimators': 130}. Best is trial 26 with value: 0.7200669505233457.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:21:53,142]\u001b[0m Trial 31 finished with value: 0.7187422296047525 and parameters: {'rf_max_depth': 17, 'rf_max_leaves': 39, 'rf_n_estimators': 140}. Best is trial 26 with value: 0.7200669505233457.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:23:13,641]\u001b[0m Trial 32 finished with value: 0.7178982032887722 and parameters: {'rf_max_depth': 15, 'rf_max_leaves': 40, 'rf_n_estimators': 140}. Best is trial 26 with value: 0.7200669505233457.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:24:06,958]\u001b[0m Trial 33 finished with value: 0.7201882303446174 and parameters: {'rf_max_depth': 16, 'rf_max_leaves': 38, 'rf_n_estimators': 110}. Best is trial 33 with value: 0.7201882303446174.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:25:00,132]\u001b[0m Trial 34 finished with value: 0.7153691708435186 and parameters: {'rf_max_depth': 23, 'rf_max_leaves': 38, 'rf_n_estimators': 110}. Best is trial 33 with value: 0.7201882303446174.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:25:46,337]\u001b[0m Trial 35 finished with value: 0.7166945445841162 and parameters: {'rf_max_depth': 16, 'rf_max_leaves': 40, 'rf_n_estimators': 90}. Best is trial 33 with value: 0.7201882303446174.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:26:45,312]\u001b[0m Trial 36 finished with value: 0.7160922800171184 and parameters: {'rf_max_depth': 18, 'rf_max_leaves': 36, 'rf_n_estimators': 130}. Best is trial 33 with value: 0.7201882303446174.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:27:32,308]\u001b[0m Trial 37 finished with value: 0.7139236053183232 and parameters: {'rf_max_depth': 13, 'rf_max_leaves': 38, 'rf_n_estimators': 100}. Best is trial 33 with value: 0.7201882303446174.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:28:30,255]\u001b[0m Trial 38 finished with value: 0.7204283963064783 and parameters: {'rf_max_depth': 17, 'rf_max_leaves': 39, 'rf_n_estimators': 120}. Best is trial 38 with value: 0.7204283963064783.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:29:12,955]\u001b[0m Trial 39 finished with value: 0.7176588352204725 and parameters: {'rf_max_depth': 22, 'rf_max_leaves': 40, 'rf_n_estimators': 80}. Best is trial 38 with value: 0.7204283963064783.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:30:12,154]\u001b[0m Trial 40 finished with value: 0.7191037479236633 and parameters: {'rf_max_depth': 19, 'rf_max_leaves': 38, 'rf_n_estimators': 120}. Best is trial 38 with value: 0.7204283963064783.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:31:14,785]\u001b[0m Trial 41 finished with value: 0.7186214575339287 and parameters: {'rf_max_depth': 17, 'rf_max_leaves': 39, 'rf_n_estimators': 130}. Best is trial 38 with value: 0.7204283963064783.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:32:08,971]\u001b[0m Trial 42 finished with value: 0.7212732205160195 and parameters: {'rf_max_depth': 16, 'rf_max_leaves': 39, 'rf_n_estimators': 110}. Best is trial 42 with value: 0.7212732205160195.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:33:02,655]\u001b[0m Trial 43 finished with value: 0.7174170734714898 and parameters: {'rf_max_depth': 13, 'rf_max_leaves': 40, 'rf_n_estimators': 110}. Best is trial 42 with value: 0.7212732205160195.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:33:54,669]\u001b[0m Trial 44 finished with value: 0.7151294400963274 and parameters: {'rf_max_depth': 16, 'rf_max_leaves': 39, 'rf_n_estimators': 90}. Best is trial 42 with value: 0.7212732205160195.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:34:55,036]\u001b[0m Trial 45 finished with value: 0.7176584000058029 and parameters: {'rf_max_depth': 20, 'rf_max_leaves': 38, 'rf_n_estimators': 100}. Best is trial 42 with value: 0.7212732205160195.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:35:55,340]\u001b[0m Trial 46 finished with value: 0.7112751789820329 and parameters: {'rf_max_depth': 12, 'rf_max_leaves': 39, 'rf_n_estimators': 120}. Best is trial 42 with value: 0.7212732205160195.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:37:03,690]\u001b[0m Trial 47 finished with value: 0.7125980865061692 and parameters: {'rf_max_depth': 14, 'rf_max_leaves': 40, 'rf_n_estimators': 110}. Best is trial 42 with value: 0.7212732205160195.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:38:23,266]\u001b[0m Trial 48 finished with value: 0.7195864735280677 and parameters: {'rf_max_depth': 18, 'rf_max_leaves': 38, 'rf_n_estimators': 140}. Best is trial 42 with value: 0.7212732205160195.\u001b[0m\n",
      "\u001b[32m[I 2021-04-14 15:39:23,180]\u001b[0m Trial 49 finished with value: 0.7085033692869008 and parameters: {'rf_max_depth': 14, 'rf_max_leaves': 37, 'rf_n_estimators': 80}. Best is trial 42 with value: 0.7212732205160195.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Invoke suggest methods of a Trial object to generate hyperparameters.\n",
    "    \n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 2, 32)\n",
    "    rf_max_leaves = trial.suggest_int('rf_max_leaves', 30, 40)\n",
    "    rf_n_estimators = trial.suggest_int('rf_n_estimators', 10, 150, step=10)\n",
    "    clf= lgb.LGBMClassifier(max_depth=rf_max_depth, num_leaves=rf_max_leaves, n_estimators=rf_n_estimators ,n_jobs=-1)\n",
    "\n",
    "    accuracies = []\n",
    "    for i in range(5):\n",
    "        train_x = train.query(f'fold!={i}').drop(['fold', 'target'], axis=1).reset_index(drop=True)\n",
    "        train_y = train.query(f'fold!={i}').target.reset_index(drop=True)\n",
    "        valid_x = train.query(f'fold=={i}').drop(['fold', 'target'], axis=1).reset_index(drop=True)\n",
    "        valid_y = train.query(f'fold=={i}').target.reset_index(drop=True)\n",
    "        clf.fit(train_x, train_y)\n",
    "        probs = clf.predict_proba(valid_x)\n",
    "        accuracies.append(accuracy_score(valid_y, probs.argmax(1)))\n",
    "\n",
    "    return np.mean(accuracies)  # An objective value linked with the Trial object.\n",
    "\n",
    "study = optuna.create_study(direction='maximize')  # Create a new study.\n",
    "study.optimize(objective, n_trials=50)  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-13 22:23:20,288]\u001b[0m A new study created in memory with name: no-name-9efd70a8-cf31-4cbc-b2f6-11637cc46433\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:23:36,673]\u001b[0m Trial 0 finished with value: 0.7087449134285487 and parameters: {'rf_max_depth': 28, 'rf_max_leaves': 40, 'rf_n_estimators': 30}. Best is trial 0 with value: 0.7087449134285487.\u001b[0m\n",
      "\u001b[33m[W 2021-04-13 22:24:05,970]\u001b[0m Trial 1 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:24:37,593]\u001b[0m Trial 2 finished with value: 0.7158518964479229 and parameters: {'rf_max_depth': 23, 'rf_max_leaves': 34, 'rf_n_estimators': 80}. Best is trial 2 with value: 0.7158518964479229.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:24:51,402]\u001b[0m Trial 3 finished with value: 0.7136838745711321 and parameters: {'rf_max_depth': 16, 'rf_max_leaves': 39, 'rf_n_estimators': 30}. Best is trial 2 with value: 0.7158518964479229.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:25:31,655]\u001b[0m Trial 4 finished with value: 0.7176580373269115 and parameters: {'rf_max_depth': 30, 'rf_max_leaves': 37, 'rf_n_estimators': 100}. Best is trial 4 with value: 0.7176580373269115.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:26:02,487]\u001b[0m Trial 5 finished with value: 0.7115186090539158 and parameters: {'rf_max_depth': 22, 'rf_max_leaves': 30, 'rf_n_estimators': 90}. Best is trial 4 with value: 0.7176580373269115.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:26:44,786]\u001b[0m Trial 6 finished with value: 0.7175385709000965 and parameters: {'rf_max_depth': 25, 'rf_max_leaves': 40, 'rf_n_estimators': 100}. Best is trial 4 with value: 0.7176580373269115.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:26:55,628]\u001b[0m Trial 7 finished with value: 0.7030835684701477 and parameters: {'rf_max_depth': 3, 'rf_max_leaves': 30, 'rf_n_estimators': 110}. Best is trial 4 with value: 0.7176580373269115.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:27:18,885]\u001b[0m Trial 8 finished with value: 0.7064551039800382 and parameters: {'rf_max_depth': 18, 'rf_max_leaves': 33, 'rf_n_estimators': 60}. Best is trial 4 with value: 0.7176580373269115.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:27:24,479]\u001b[0m Trial 9 finished with value: 0.6930866875086136 and parameters: {'rf_max_depth': 23, 'rf_max_leaves': 36, 'rf_n_estimators': 10}. Best is trial 4 with value: 0.7176580373269115.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:28:05,344]\u001b[0m Trial 10 finished with value: 0.7200668779875674 and parameters: {'rf_max_depth': 24, 'rf_max_leaves': 37, 'rf_n_estimators': 100}. Best is trial 10 with value: 0.7200668779875674.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:28:50,969]\u001b[0m Trial 11 finished with value: 0.7152505748460427 and parameters: {'rf_max_depth': 9, 'rf_max_leaves': 38, 'rf_n_estimators': 140}. Best is trial 10 with value: 0.7200668779875674.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:29:42,064]\u001b[0m Trial 12 finished with value: 0.7172989126886837 and parameters: {'rf_max_depth': 31, 'rf_max_leaves': 37, 'rf_n_estimators': 130}. Best is trial 10 with value: 0.7200668779875674.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:30:28,491]\u001b[0m Trial 13 finished with value: 0.7177775762895047 and parameters: {'rf_max_depth': 32, 'rf_max_leaves': 35, 'rf_n_estimators': 120}. Best is trial 10 with value: 0.7200668779875674.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:31:11,511]\u001b[0m Trial 14 finished with value: 0.696935580975316 and parameters: {'rf_max_depth': 31, 'rf_max_leaves': 33, 'rf_n_estimators': 120}. Best is trial 10 with value: 0.7200668779875674.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:32:06,016]\u001b[0m Trial 15 finished with value: 0.7200678934884632 and parameters: {'rf_max_depth': 16, 'rf_max_leaves': 35, 'rf_n_estimators': 150}. Best is trial 15 with value: 0.7200678934884632.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:32:58,982]\u001b[0m Trial 16 finished with value: 0.7047639323096117 and parameters: {'rf_max_depth': 13, 'rf_max_leaves': 35, 'rf_n_estimators': 150}. Best is trial 15 with value: 0.7200678934884632.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:33:19,124]\u001b[0m Trial 17 finished with value: 0.7142874447821388 and parameters: {'rf_max_depth': 10, 'rf_max_leaves': 32, 'rf_n_estimators': 60}. Best is trial 15 with value: 0.7200678934884632.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:34:16,872]\u001b[0m Trial 18 finished with value: 0.7015244119161776 and parameters: {'rf_max_depth': 18, 'rf_max_leaves': 37, 'rf_n_estimators': 150}. Best is trial 15 with value: 0.7200678934884632.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:34:25,616]\u001b[0m Trial 19 finished with value: 0.7027200916852238 and parameters: {'rf_max_depth': 4, 'rf_max_leaves': 36, 'rf_n_estimators': 60}. Best is trial 15 with value: 0.7200678934884632.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:35:20,768]\u001b[0m Trial 20 finished with value: 0.721873018866556 and parameters: {'rf_max_depth': 20, 'rf_max_leaves': 38, 'rf_n_estimators': 140}. Best is trial 20 with value: 0.721873018866556.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:36:18,567]\u001b[0m Trial 21 finished with value: 0.7230796515381211 and parameters: {'rf_max_depth': 14, 'rf_max_leaves': 39, 'rf_n_estimators': 150}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:37:17,442]\u001b[0m Trial 22 finished with value: 0.7195842249189413 and parameters: {'rf_max_depth': 14, 'rf_max_leaves': 39, 'rf_n_estimators': 150}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[33m[W 2021-04-13 22:38:13,798]\u001b[0m Trial 23 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:39:10,875]\u001b[0m Trial 24 finished with value: 0.7212724951582368 and parameters: {'rf_max_depth': 20, 'rf_max_leaves': 39, 'rf_n_estimators': 140}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:40:03,508]\u001b[0m Trial 25 finished with value: 0.7160918448024487 and parameters: {'rf_max_depth': 21, 'rf_max_leaves': 39, 'rf_n_estimators': 130}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:40:56,599]\u001b[0m Trial 26 finished with value: 0.7094632352407825 and parameters: {'rf_max_depth': 20, 'rf_max_leaves': 40, 'rf_n_estimators': 130}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:41:45,564]\u001b[0m Trial 27 finished with value: 0.7017609510891247 and parameters: {'rf_max_depth': 10, 'rf_max_leaves': 38, 'rf_n_estimators': 140}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:42:40,784]\u001b[0m Trial 28 finished with value: 0.7180213690402791 and parameters: {'rf_max_depth': 26, 'rf_max_leaves': 38, 'rf_n_estimators': 140}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:43:28,610]\u001b[0m Trial 29 finished with value: 0.7103095827016676 and parameters: {'rf_max_depth': 13, 'rf_max_leaves': 39, 'rf_n_estimators': 120}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:44:25,949]\u001b[0m Trial 30 finished with value: 0.7164540159433641 and parameters: {'rf_max_depth': 19, 'rf_max_leaves': 40, 'rf_n_estimators': 140}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:45:10,928]\u001b[0m Trial 31 finished with value: 0.7183791880344981 and parameters: {'rf_max_depth': 27, 'rf_max_leaves': 38, 'rf_n_estimators': 110}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:45:44,932]\u001b[0m Trial 32 finished with value: 0.716694762191451 and parameters: {'rf_max_depth': 6, 'rf_max_leaves': 40, 'rf_n_estimators': 150}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:46:41,074]\u001b[0m Trial 33 finished with value: 0.7200683287031329 and parameters: {'rf_max_depth': 16, 'rf_max_leaves': 36, 'rf_n_estimators': 150}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:47:31,000]\u001b[0m Trial 34 finished with value: 0.7135660039314391 and parameters: {'rf_max_depth': 15, 'rf_max_leaves': 36, 'rf_n_estimators': 130}. Best is trial 21 with value: 0.7230796515381211.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:48:23,931]\u001b[0m Trial 35 finished with value: 0.7251263210578618 and parameters: {'rf_max_depth': 12, 'rf_max_leaves': 39, 'rf_n_estimators': 140}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:49:17,141]\u001b[0m Trial 36 finished with value: 0.7211501998360692 and parameters: {'rf_max_depth': 12, 'rf_max_leaves': 39, 'rf_n_estimators': 140}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:49:50,383]\u001b[0m Trial 37 finished with value: 0.7058517513763664 and parameters: {'rf_max_depth': 7, 'rf_max_leaves': 38, 'rf_n_estimators': 120}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:50:26,722]\u001b[0m Trial 38 finished with value: 0.7157298912688683 and parameters: {'rf_max_depth': 21, 'rf_max_leaves': 39, 'rf_n_estimators': 80}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:51:19,683]\u001b[0m Trial 39 finished with value: 0.7074182340439422 and parameters: {'rf_max_depth': 17, 'rf_max_leaves': 40, 'rf_n_estimators': 110}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:52:08,843]\u001b[0m Trial 40 finished with value: 0.7183817267867375 and parameters: {'rf_max_depth': 11, 'rf_max_leaves': 39, 'rf_n_estimators': 130}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:52:40,220]\u001b[0m Trial 41 finished with value: 0.7168168399062838 and parameters: {'rf_max_depth': 8, 'rf_max_leaves': 40, 'rf_n_estimators': 90}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:52:53,772]\u001b[0m Trial 42 finished with value: 0.7122398322972806 and parameters: {'rf_max_depth': 19, 'rf_max_leaves': 37, 'rf_n_estimators': 30}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:53:49,387]\u001b[0m Trial 43 finished with value: 0.7136838745711322 and parameters: {'rf_max_depth': 12, 'rf_max_leaves': 39, 'rf_n_estimators': 140}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:54:43,040]\u001b[0m Trial 44 finished with value: 0.7064549589084816 and parameters: {'rf_max_depth': 14, 'rf_max_leaves': 38, 'rf_n_estimators': 140}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:55:36,957]\u001b[0m Trial 45 finished with value: 0.7211507801222954 and parameters: {'rf_max_depth': 12, 'rf_max_leaves': 40, 'rf_n_estimators': 140}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:56:31,329]\u001b[0m Trial 46 finished with value: 0.7210335623046068 and parameters: {'rf_max_depth': 22, 'rf_max_leaves': 40, 'rf_n_estimators': 130}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:57:22,064]\u001b[0m Trial 47 finished with value: 0.6989916076104539 and parameters: {'rf_max_depth': 24, 'rf_max_leaves': 39, 'rf_n_estimators': 120}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:58:22,628]\u001b[0m Trial 48 finished with value: 0.6987445507496572 and parameters: {'rf_max_depth': 17, 'rf_max_leaves': 40, 'rf_n_estimators': 150}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n",
      "\u001b[32m[I 2021-04-13 22:59:16,531]\u001b[0m Trial 49 finished with value: 0.7199464685956348 and parameters: {'rf_max_depth': 15, 'rf_max_leaves': 37, 'rf_n_estimators': 140}. Best is trial 35 with value: 0.7251263210578618.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Invoke suggest methods of a Trial object to generate hyperparameters.\n",
    "    \n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 2, 32)\n",
    "    rf_max_leaves = trial.suggest_int('rf_max_leaves', 30, 40)\n",
    "    rf_n_estimators = trial.suggest_int('rf_n_estimators', 10, 150, step=10)\n",
    "    clf= lgb.LGBMClassifier(max_depth=rf_max_depth, num_leaves=rf_max_leaves, n_estimators=rf_n_estimators ,n_jobs=-1)\n",
    "\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    scoring = ['accuracy', 'neg_log_loss']\n",
    "    scores = cross_validate(clf, X, y, cv=cv, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "    accuracy_score = scores['test_accuracy'].mean()\n",
    "\n",
    "    return accuracy_score  # An objective value linked with the Trial object.\n",
    "\n",
    "study = optuna.create_study(direction='maximize')  # Create a new study.\n",
    "study.optimize(objective, n_trials=50)  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v968</th>\n",
       "      <th>v969</th>\n",
       "      <th>v970</th>\n",
       "      <th>v971</th>\n",
       "      <th>v972</th>\n",
       "      <th>v973</th>\n",
       "      <th>v974</th>\n",
       "      <th>v975</th>\n",
       "      <th>v976</th>\n",
       "      <th>v977</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8297</th>\n",
       "      <td>20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8298</th>\n",
       "      <td>20</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8299</th>\n",
       "      <td>20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8300</th>\n",
       "      <td>20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>20</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8302 rows × 979 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      problem_id    v0    v1    v2    v3    v4    v5    v6    v7    v8  ...  \\\n",
       "0              0  0.35  0.36  0.77  0.42  0.48  0.12  0.43  0.49  0.19  ...   \n",
       "1              0  0.12  0.17  0.38  0.43  0.57  0.09  0.11  0.58  0.35  ...   \n",
       "2              0  0.67  0.16  0.85  0.41  0.57  0.27  0.83  0.73  0.26  ...   \n",
       "3              0  0.70  0.20  0.62  0.41  0.41  0.10  0.80  0.52  0.82  ...   \n",
       "4              0  0.72  0.75  0.74  0.42  0.41  0.76  0.34  0.72  0.06  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "8297          20  0.91  0.76  0.45  0.81  0.99  0.20  0.36  0.28  0.02  ...   \n",
       "8298          20  0.31  0.93  0.45  0.61  0.99  0.09  0.73  0.25  0.56  ...   \n",
       "8299          20  0.92  0.82  0.52  0.61  0.94  0.67  0.65  0.34  0.25  ...   \n",
       "8300          20  0.93  0.85  0.51  0.64  0.95  0.76  0.76  0.36  0.07  ...   \n",
       "8301          20  0.87  0.14  0.52  0.64  0.03  0.94  0.45  0.50  0.12  ...   \n",
       "\n",
       "      v968  v969  v970  v971  v972  v973  v974  v975  v976  v977  \n",
       "0     1.00  0.77  0.57  0.56  0.40  0.75  0.08  0.14  0.43  0.88  \n",
       "1     0.39  0.07  0.59  0.06  0.17  0.09  0.04  0.04  0.45  0.14  \n",
       "2     0.65  0.24  0.42  0.57  0.58  0.37  0.01  0.10  0.38  0.06  \n",
       "3     0.96  0.04  0.52  0.25  0.07  0.23  0.04  0.76  0.41  0.59  \n",
       "4     0.99  0.81  0.41  0.16  0.03  0.21  0.10  0.12  0.53  0.30  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "8297  0.81  0.75  0.92  0.86  0.84  0.86  0.52  0.04  0.77  0.68  \n",
       "8298  0.53  0.36  0.93  0.61  0.65  0.65  0.31  0.06  0.89  0.11  \n",
       "8299  0.40  0.80  0.74  0.94  0.76  0.61  0.72  0.14  0.11  0.91  \n",
       "8300  0.71  0.33  0.92  0.24  0.89  0.84  0.54  0.13  0.91  0.95  \n",
       "8301  0.39  0.46  0.83  0.72  0.78  0.75  0.71  0.38  0.19  0.91  \n",
       "\n",
       "[8302 rows x 979 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X.drop('obs_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit():\n",
    "    # logic: train 5 folds and take the average of the probabilities\n",
    "    PROBS = []\n",
    "    clf= lgb.LGBMClassifier(max_depth = 12, num_leaves = 39, n_estimators = 140)\n",
    "    for i in range(5):\n",
    "        train_x = train.query(f'fold!={i}').drop(['fold', 'target'], axis=1).reset_index(drop=True)\n",
    "        train_y = train.query(f'fold!={i}').target.reset_index(drop=True)\n",
    "        clf.fit(train_x, train_y)\n",
    "        probs = clf.predict_proba(test_X)\n",
    "        PROBS.append(probs)\n",
    "    return np.array(PROBS).mean(0).argmax(1)  # 5 * probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = {'max_depth': 12, 'num_leaves': 39, 'n_estimators': 140, 'n_jobs' : -1}\n",
    "clf= lgb.LGBMClassifier(max_depth = 12, num_leaves = 39, n_estimators = 140, n_jobs=-1)\n",
    "clf.fit(X,y)\n",
    "pred = clf.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv('sample_submission (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['target'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1195\n",
       "1     757\n",
       "2      78\n",
       "4       9\n",
       "3       2\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('submission_5fold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= lgb.LGBMClassifier(n_jobs=-1)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "scoring = ['accuracy', 'neg_log_loss']\n",
    "scores = cross_validate(clf, X, y, cv=cv, n_jobs=-1, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([38.44742298, 38.27774382, 37.89593005, 37.49605989, 37.64017415]),\n",
       " 'score_time': array([0.38174415, 0.38211513, 0.46092176, 0.52381229, 0.48865294]),\n",
       " 'test_accuracy': array([0.70860927, 0.70860927, 0.70963855, 0.72951807, 0.7060241 ]),\n",
       " 'test_neg_log_loss': array([-0.70949581, -0.7108665 , -0.71399456, -0.69770164, -0.76142708])}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
